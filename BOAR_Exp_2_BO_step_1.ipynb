{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Design of Experiments to optimize perovskite solar cells efficiency\n",
    "Version 1.0.0\n",
    "(c) Vincent M. Le Corre, Larry Lueer, i-MEET 2021-2023"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is made to use BOAR to design experiments. Here, we show how to load some data from a presampling, and how to use BOAR to suggest the next set of experiment using Bayesian optimization.\n",
    "The goal here is to optimize the processing conditions for a perovskite solar cell to maximize the power conversion efficiency (PCE).\n",
    "\n",
    "Note: The data used here is real data generated in the [i-MEET](https://www.i-meet.ww.uni-erlangen.de/) and [HI-ERN](https://www.hi-ern.de/de) labs at the university of Erlangen-Nuremberg (FAU) by Jiyun Zang. The data is not published yet, and is only used here for demonstration purposes. For more information, please contact us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activate matplotlib widgets\n",
    "%matplotlib inline\n",
    "# comment the next line if you are on the jupyterhub server\n",
    "%matplotlib widget \n",
    "# %matplotlib notebook\n",
    "# import plotly.io as pio # comment out to only render png\n",
    "# pio.renderers.default = 'png'coconda activate pero\n",
    "\n",
    "# Import libraries\n",
    "import sys,os,types,copy\n",
    "import warnings\n",
    "import pandas as pd\n",
    "warnings.filterwarnings('ignore') # comment this out to see warnings\n",
    "\n",
    "# Import boar\n",
    "# sys.path.append('/home/vlc/Desktop/boar') # comment out if the Notebook is in the Notebooks folder\n",
    "from boar import *\n",
    "# import boar\n",
    "from boar.core.optimization_botorch import *\n",
    "# import additional libraries from Ax\n",
    "from ax.utils.notebook.plotting import render, init_notebook_plotting # for plotting in notebook\n",
    "from ax.plot.slice import plot_slice\n",
    "from ax.plot.scatter import interact_fitted,plot_objective_vs_constraints,tile_fitted\n",
    "from ax.modelbridge.cross_validation import cross_validate\n",
    "from ax.plot.contour import interact_contour\n",
    "from ax.plot.diagnostic import interact_cross_validation\n",
    "from ax.plot.pareto_utils import compute_posterior_pareto_frontier\n",
    "from ax.plot.pareto_frontier import plot_pareto_frontier\n",
    "# Import homemade package by VLC\n",
    "# import boar.SIMsalabim_utils.plot_settings_screen # to set default plot settings\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to the data \n",
    "curr_dir = os.getcwd() # current directory\n",
    "# res_dir = os.path.join(os.path.abspath('../'),'temp') # path to the results directory\n",
    "res_dir = os.path.join(curr_dir ,'temp') # path to the results directory\n",
    "# data_dir = os.path.join(os.path.abspath('../'),'Example_Data') \n",
    "data_dir = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names =['Spin_Speed_1_PbI2', 'Duration_t1', 'Spin_Speed_2_FAI', 'FAI_Dispense_Speed','Duration_t3', 'Spin_Speed_3', 'Pmax']\n",
    "df = pd.read_excel(os.path.join(data_dir,'BOAR_Exp_2_Round 1.xlsx'),usecols=[0,1,2,3,4,5,11],names=names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# names =['No.', 'Spin_Speed_1', 'Duration_t1', 'Spin_Speed_2', 'Dispense_Speed','Duration_t3', 'Spin_Speed_3', 'Pmax']\n",
    "# df = pd.read_excel(os.path.join(data_dir,'Jiyun','Inital Data Set LHS + Devices Results.xlsx'),'First Round',skiprows=[0,2],usecols=[0,3,4,5,6,7,10,17],names=names)\n",
    "# df = df.dropna()\n",
    "# df = df.reset_index(drop=True)\n",
    "\n",
    "# # print stats on the data\n",
    "# print(df.describe())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# names =['No.', 'Spin_Speed_1', 'Duration_t1', 'Spin_Speed_2', 'Dispense_Speed','Duration_t3', 'Spin_Speed_3', 'Pmax']\n",
    "# df_BO = pd.read_excel(os.path.join(data_dir,'Jiyun','Second Round Parameter Set+ Devices Results.xlsx'),usecols=[0,1,2,3,4,5,6,11],names=names)\n",
    "# df_BO = df_BO.dropna()\n",
    "# df_BO = df_BO.reset_index(drop=True)\n",
    "# df_BO['Pmax'] = abs(df_BO['Pmax'])\n",
    "# # print stats on the data\n",
    "# print(df_BO.describe())\n",
    "\n",
    "# # Concatenate the two dataframes\n",
    "# df = pd.concat([df,df_BO],axis=0)\n",
    "# df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_names = names[0:-1]\n",
    "target_names = [names[-1]]\n",
    "df_filtered = copy.deepcopy(df[params_names+target_names])\n",
    "df_filtered = df_filtered.drop_duplicates()\n",
    "df_filtered = df_filtered.dropna()\n",
    "\n",
    "\n",
    "dic = {'x':[],'y_0':[],'ydyn_0':1}\n",
    "for num in range(len(df_filtered)):\n",
    "    dic['x'].append(df_filtered[params_names].iloc[num].values.tolist())\n",
    "    dic['y_0'].append(df_filtered[target_names[0]].iloc[num])\n",
    "    \n",
    "\n",
    "# save to res_dir\n",
    "with open(os.path.join(res_dir,'old_XY.json'), 'w') as fp:\n",
    "    json.dump(dic, fp)\n",
    "\n",
    "print(dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import boar.SIMsalabim_utils.plot_settings_screen # to set default plot settings\n",
    "best_pmax = []\n",
    "best_random = 0\n",
    "plt.figure(figsize=(12,10))\n",
    "for idx,p in enumerate(df['Pmax']):\n",
    "    if idx == 0:\n",
    "        best_pmax.append(p)\n",
    "    else:\n",
    "        if p > best_pmax[-1]:\n",
    "            best_pmax.append(p)\n",
    "            if idx < 30:\n",
    "                best_random = p\n",
    "        else:\n",
    "            best_pmax.append(best_pmax[-1])\n",
    "\n",
    "df['Best Pmax'] = best_pmax\n",
    "\n",
    "plt.plot(df['Pmax'],'C0o')\n",
    "plt.plot(df['Best Pmax'],'C3--')\n",
    "plt.plot([0,50],[best_random,best_random],'C2-.')\n",
    "\n",
    "plt.xlabel('Experiment No.')\n",
    "plt.ylabel('PCE [%]')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(dic['y_0']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the free parameters to be optimized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = []\n",
    "\n",
    "Spin_Speed_1 = Fitparam(name = 'Spin_Speed_1_PbI2', val =  1000, lims = [900, 3000], relRange = 1, range_type = 'lin',\n",
    "            lim_type = 'absolute',optim_type='lin', display_name = 'Spin Speed 1', unit = 'RPM',val_type='int',rescale=False)\n",
    "params.append(Spin_Speed_1)\n",
    "Duration_t1 = Fitparam(name = 'Duration_t1', val =  15, lims = [5, 50], relRange = 1, range_type = 'lin',\n",
    "            lim_type = 'absolute',optim_type='lin', display_name = 'Duration t1', unit = 's',val_type='int'\n",
    "                        ,rescale=False)\n",
    "params.append(Duration_t1)\n",
    "Spin_Speed_2 = Fitparam(name = 'Spin_Speed_2_FAI', val =  1000, lims = [900, 3000], relRange = 1, range_type = 'lin',\n",
    "            lim_type = 'absolute',optim_type='lin', display_name = 'Spin Speed 2', unit = 'RPM',val_type='int'\n",
    "                        ,rescale=False)\n",
    "params.append(Spin_Speed_2)\n",
    "Dispense_Speed = Fitparam(name = 'FAI_Dispense_Speed', val =  100, lims = [10, 400], relRange = 1, range_type = 'lin',\n",
    "            lim_type = 'absolute',optim_type='lin', display_name = 'Dispense Speed', unit = '',val_type='int'\n",
    "                        ,rescale=False)\n",
    "params.append(Dispense_Speed)\n",
    "Duration_t3 = Fitparam(name = 'Duration_t3', val =  10, lims = [5, 45], relRange = 1, range_type = 'lin',\n",
    "            lim_type = 'absolute',optim_type='lin', display_name = 'Duration t3', unit = 's',val_type='int'\n",
    "                        ,rescale=False)\n",
    "params.append(Duration_t3)\n",
    "Spin_Speed_3 = Fitparam(name = 'Spin_Speed_3', val =  1000, lims = [1000, 5000], relRange = 1, range_type = 'lin',\n",
    "            lim_type = 'absolute',optim_type='lin', display_name = 'Spin Speed 3', unit = 'RPM',val_type='int',rescale=False)\n",
    "params.append(Spin_Speed_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an excel file with len(params) columns and nb_new_exp rows filled with nan\n",
    "nb_new_exp = 9\n",
    "dat_array = np.zeros((nb_new_exp, len(params))).tolist()\n",
    "# replace all with 'nan'\n",
    "for i in range(len(dat_array)):\n",
    "    for j in range(len(dat_array[i])):\n",
    "        dat_array[i][j] = 'nan'\n",
    "pnames = [ p.name for p in params ]\n",
    "df_ = pd.DataFrame(dat_array, columns=pnames)\n",
    "df_.to_excel(os.path.join(res_dir,'BOAR_Exp.xlsx'), index=False)\n",
    "\n",
    "df2 = pd.read_excel(os.path.join(res_dir,'BOAR_Exp.xlsx'))\n",
    "print(df2)\n",
    "def exp_to_df(X,params):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start the optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the targets and the model for the TM problem\n",
    "X_dimensions = ['_']\n",
    "y_dimension = 'Pmax'\n",
    "target = {'model':exp_to_df,'target_name':'Pmax','minimize':False,\n",
    "          'data':{'X':[0],'y':[0],'X_dimensions':X_dimensions,'X_units':['V',''],'y_dimension':y_dimension,'y_unit':'mW cm$^{-2}$'}\n",
    "            ,'target_weight':1, 'weight':1}\n",
    "\n",
    "\n",
    "targets = [target]\n",
    "obj_type='identity'\n",
    "loss='linear'\n",
    "threshold=[18]\n",
    "\n",
    "mo = MooBOtorch(params=params, targets= targets) # initialize the optimization object\n",
    "mo.warmstart = 'recall'\n",
    "mo.parallel = True # needed if number of cores is lower than number of CPU - 1 to ensure we output the right number of points\n",
    "# mo.SaveOldXY2file = os.path.join(res_dir,'old_XY.json')\n",
    "mo.Path2OldXY = os.path.join(res_dir,'old_XY.json')\n",
    "# mo.parameter_constraints = [f'{stepsize_fraction}*Cs_fraction + {stepsize_fraction}*Fa_fraction <= 1']\n",
    "\n",
    "# Define custom evaluation function\n",
    "def evaluate_custom(self,px,obj_type,loss,threshold=1,is_MOO=True):\n",
    "  pass\n",
    "  \n",
    "\n",
    "mo.evaluate_custom = types.MethodType(evaluate_custom, mo) # add the method to the object FullyBayesianMOO\n",
    "kwargs_posterior = {'Nres':10,'Ninteg':1e3,'logscale':True,'vmin':1e-100,'zoom':0,'min_prob':1e-40,'clear_axis':False,'True_values':None,'show_points':True,'savefig':False,'figname':'param_posterior','full_grid':True,'randomize':True}\n",
    "\n",
    "ax_client = mo.BoTorchOpti(n_jobs=[nb_new_exp], n_step_points = [nb_new_exp], models=['FullyBayesian'],obj_type=obj_type,loss=loss,threshold=threshold,use_CUDA=True,is_MOO=False,verbose=True,show_posterior=False,kwargs_posterior=kwargs_posterior,use_custom_func=True,suggest_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the optimized parameters\n",
    "for p in mo.params:\n",
    "    if p.val_type != 'str':\n",
    "        print(p.display_name + f' {p.val:.0f} ')\n",
    "        print(p.lims)\n",
    "    else:\n",
    "        print(p.display_name + f' {p.val}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all tried data from the ax_client\n",
    "triedX = ax_client.generation_strategy.trials_as_df\n",
    "# print(triedX.tail())\n",
    "triedY = ax_client.experiment.fetch_data().df\n",
    "# print(triedY.tail())\n",
    "\n",
    "# find Trial Status ABANDONED\n",
    "abandoned_trials = triedX[triedX['Trial Status']=='ABANDONED']\n",
    "dics = []\n",
    "for index, row in abandoned_trials.iterrows():\n",
    "    \n",
    "    dic_dum = abandoned_trials['Arm Parameterizations'][index]\n",
    "    key = list(dic_dum.keys())[0]\n",
    "    dic = dic_dum[key]\n",
    "    dics.append(dic)\n",
    "\n",
    "# put in a dataframe\n",
    "df2try = pd.DataFrame(dics)\n",
    "\n",
    "# save to excel\n",
    "df2try.to_excel(os.path.join(res_dir,'BOAR_Exp_2_try.xlsx'), index=False)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the Pareto front of the test problem\n",
    "mo.plot_all_objectives(ax_client,logscale=False,figsize=(10,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the density of points that were sampled during the optimization process\n",
    "# import boar.SIMsalabim_utils.plot_settings_screen # to set default plot settings\n",
    "mo.plot_density(ax_client,figsize=(10,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the contour of the objective function for a given target\n",
    "\n",
    "render(ax_client.get_contour_plot(param_x=params[0].name, param_y=params[-1].name, metric_name=obj_type))\n",
    "render(ax_client.get_contour_plot(param_x=params[0].name, param_y=params[1].name, metric_name=obj_type))\n",
    "render(ax_client.get_contour_plot(param_x=params[0].name, param_y=params[-2].name, metric_name=obj_type))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the slice (i.e., 1D projection) of the model along the a single dimension \n",
    "model = ax_client.generation_strategy.model\n",
    "\n",
    "render(plot_slice(model, params[-1].name, obj_type))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ax\n",
    "x = ax.plot.slice.plot_slice(model=model,param_name= params[-1].name, metric_name= obj_type).data['data'][1]['x']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results of cross validation\n",
    "cv_results = cross_validate(model)\n",
    "render(interact_cross_validation(cv_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive plot of the target during the optimization process\n",
    "render(interact_fitted(model, rel=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
